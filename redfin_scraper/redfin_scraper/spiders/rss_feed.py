import yaml
import feedparser
import scrapy
from datetime import datetime
from dateutil import parser as dtp
from pathlib import Path
from ..items import RawRSSItem, ProcessedItem, PublicItem, ContentType, Language
import json
from urllib.parse import urlparse
from typing import Optional, List, Dict, Any
import os

class RssFeedSpider(scrapy.Spider):
    name = "rss_feed"

    def start_requests(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ feeds.yaml ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        feeds_path = os.getenv('FEEDS_CONFIG_PATH', 'feeds/feeds.yaml')
        
        self.logger.info(f"ðŸ” feeds.yaml ê²½ë¡œ: {feeds_path}")
        
        try:
            with open(feeds_path, "r", encoding="utf-8") as f:
                cfg = yaml.safe_load(f) or {}
                self.logger.info(f"âœ… feeds.yaml ë¡œë“œ ì™„ë£Œ: {len(cfg.get('feeds', []))}ê°œ í”¼ë“œ")
        except FileNotFoundError:
            self.logger.warning(f"feeds.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {feeds_path}")
            # ê¸°ë³¸ RSS í”¼ë“œ ì‚¬ìš©
            cfg = {
                "feeds": [
                    {"name": "test_feed", "url": "https://httpbin.org/xml"},
                    {"name": "sample_rss", "url": "https://feeds.bbci.co.uk/news/rss.xml"}
                ]
            }
            self.logger.info(f"ðŸ”„ ê¸°ë³¸ í”¼ë“œ ì‚¬ìš©: {len(cfg.get('feeds', []))}ê°œ")
        
        for src in cfg.get("feeds", []):
            url = src["url"]
            self.logger.info(f"ðŸ“¡ ìš”ì²­ ìƒì„±: {src.get('name', 'Unknown')} -> {url}")
            yield scrapy.Request(
                url,
                callback=self.parse_feed,
                meta={"source": src.get("name") or url},
                dont_filter=True,
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Accept': 'application/rss+xml, application/atom+xml, application/xml, text/xml'
                }
            )

    def parse_feed(self, response):
        """RSS í”¼ë“œ íŒŒì‹± ë° RawRSSItem ìƒì„±"""
        parsed = feedparser.parse(response.body)
        source = response.meta["source"]
        
        # ì‘ë‹µ í—¤ë” ì •ë³´ ì €ìž¥ (ë°”ì´íŠ¸ë¥¼ ë¬¸ìžì—´ë¡œ ë³€í™˜)
        response_headers = {}
        for key, value in response.headers.items():
            if isinstance(value, list):
                response_headers[key.decode('utf-8') if isinstance(key, bytes) else key] = [v.decode('utf-8') if isinstance(v, bytes) else v for v in value]
            else:
                response_headers[key.decode('utf-8') if isinstance(key, bytes) else key] = value.decode('utf-8') if isinstance(value, bytes) else value
        
        for e in parsed.entries:
            try:
                # ê¸°ë³¸ ì‹ë³„ ì •ë³´
                guid = e.get("id") or e.get("guid") or e.get("link")
                if not guid:
                    self.logger.warning(f"GUID not found for entry: {e.get('title', 'Unknown')}")
                    continue
                
                # ë‚ ì§œ íŒŒì‹±
                pub_date = self._parse_datetime(e.get("published") or e.get("updated") or e.get("pubDate"))
                updated = self._parse_datetime(e.get("updated"))
                
                # ì €ìž ì •ë³´ ì²˜ë¦¬
                authors = self._extract_authors(e)
                
                # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì²˜ë¦¬
                categories = self._extract_categories(e)
                dc_subjects = self._extract_dc_subjects(e)
                
                # ë¯¸ë””ì–´ ì •ë³´ ì²˜ë¦¬
                enclosure_info = self._extract_enclosure_info(e)
                media_info = self._extract_media_info(e)
                
                # ë§í¬ë¥¼ ì ˆëŒ€ URLë¡œ ë³€í™˜
                link = e.get("link", "")
                if link and not link.startswith(('http://', 'https://')):
                    link = response.urljoin(link)
                
                # RawRSSItem ìƒì„±
                raw_item = RawRSSItem(
                    # ê¸°ë³¸ ì‹ë³„ ì •ë³´
                    guid=guid,
                    source=source,
                    title=e.get("title", ""),
                    link=link,
                    comments=e.get("comments"),
                    
                    # Atom ë§í¬ ì •ë³´
                    atom_link_alternate=self._extract_atom_link(e, "alternate"),
                    atom_link_related=self._extract_atom_link(e, "related"),
                    atom_link_self=self._extract_atom_link(e, "self"),
                    feedburner_orig_link=e.get("feedburner_origlink"),
                    
                    # ì‹œê° ë° ì €ìž ì •ë³´
                    pub_date=pub_date,
                    updated=updated,
                    dc_creator=e.get("dc_creator"),
                    author=authors,
                    
                    # ë³¸ë¬¸ ì •ë³´
                    description=(e.get("summary") or e.get("description") or "").strip(),
                    content_encoded=self._extract_content_encoded(e),
                    
                    # ì¹´í…Œê³ ë¦¬ ë° íƒœê·¸
                    category=categories,
                    dc_subject=dc_subjects,
                    
                    # ë¯¸ë””ì–´ ì •ë³´
                    enclosure_url=enclosure_info.get("url"),
                    enclosure_type=enclosure_info.get("type"),
                    enclosure_length=enclosure_info.get("length"),
                    media_content=media_info.get("content"),
                    media_thumbnail=media_info.get("thumbnail"),
                    
                    # ì €ìž‘ê¶Œ ë° ë¼ì´ì„ ìŠ¤
                    copyright=e.get("rights"),
                    creative_commons_license=e.get("creativeCommons:license"),
                    
                    # ë©”íƒ€ ì •ë³´
                    source_feed=e.get("source"),
                    slash_comments=self._parse_int(e.get("slash:comments")),
                    
                    # ìˆ˜ì§‘ ë©”íƒ€
                    collected_at=datetime.now(),
                    etag=response_headers.get("etag"),
                    last_modified=response_headers.get("last-modified"),
                    raw_xml=response.text,
                    response_headers=response_headers
                )
                
                yield raw_item
                
            except Exception as e:
                self.logger.error(f"Entry íŒŒì‹± ì‹¤íŒ¨: {e}")
                if hasattr(e, 'get') and callable(e.get):
                    self.logger.error(f"Entry ì •ë³´: {e.get('title', 'Unknown')}")

    def _parse_datetime(self, date_str: Optional[str]) -> Optional[datetime]:
        """ë‚ ì§œ ë¬¸ìžì—´ì„ datetime ê°ì²´ë¡œ íŒŒì‹±"""
        if not date_str:
            return None
        
        try:
            return dtp.parse(date_str)
        except Exception:
            self.logger.warning(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_str}")
            return None

    def _extract_authors(self, entry: Dict[str, Any]) -> List[str]:
        """ì €ìž ì •ë³´ ì¶”ì¶œ"""
        authors = []
        
        # author í•„ë“œ ì²˜ë¦¬
        if "author" in entry:
            if isinstance(entry["author"], str):
                authors.append(entry["author"])
            elif isinstance(entry["author"], dict) and "name" in entry["author"]:
                authors.append(entry["author"]["name"])
        
        # dc:creator ì²˜ë¦¬
        if "dc_creator" in entry:
            dc_creator = entry["dc_creator"]
            if isinstance(dc_creator, str):
                authors.append(dc_creator)
            elif isinstance(dc_creator, list):
                authors.extend(dc_creator)
        
        return list(set(authors))  # ì¤‘ë³µ ì œê±°

    def _extract_categories(self, entry: Dict[str, Any]) -> List[str]:
        """ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ì¶œ"""
        categories = []
        
        if "category" in entry:
            category = entry["category"]
            if isinstance(category, str):
                categories.append(category)
            elif isinstance(category, list):
                categories.extend(category)
        
        return categories

    def _extract_dc_subjects(self, entry: Dict[str, Any]) -> List[str]:
        """dc:subject ì •ë³´ ì¶”ì¶œ"""
        subjects = []
        
        if "dc_subject" in entry:
            dc_subject = entry["dc_subject"]
            if isinstance(dc_subject, str):
                subjects.append(dc_subject)
            elif isinstance(dc_subject, list):
                subjects.extend(dc_subject)
        
        return subjects

    def _extract_enclosure_info(self, entry: Dict[str, Any]) -> Dict[str, Any]:
        """enclosure ì •ë³´ ì¶”ì¶œ"""
        enclosure_info = {}
        
        if "enclosures" in entry:
            enclosures = entry["enclosures"]
            if enclosures and len(enclosures) > 0:
                enclosure = enclosures[0]
                enclosure_info = {
                    "url": enclosure.get("href"),
                    "type": enclosure.get("type"),
                    "length": enclosure.get("length")
                }
        
        return enclosure_info

    def _extract_media_info(self, entry: Dict[str, Any]) -> Dict[str, Any]:
        """ë¯¸ë””ì–´ ì •ë³´ ì¶”ì¶œ"""
        media_info = {}
        
        if "media_content" in entry:
            media_content = entry["media_content"]
            if media_content and len(media_content) > 0:
                media = media_content[0]
                media_info["content"] = media.get("url")
        
        if "media_thumbnail" in entry:
            media_thumbnail = entry["media_thumbnail"]
            if media_thumbnail and len(media_thumbnail) > 0:
                thumbnail = media_thumbnail[0]
                media_info["thumbnail"] = thumbnail.get("url")
        
        return media_info

    def _extract_atom_link(self, entry: Dict[str, Any], rel: str) -> Optional[str]:
        """Atom ë§í¬ ì •ë³´ ì¶”ì¶œ"""
        if "links" in entry:
            for link in entry["links"]:
                if link.get("rel") == rel:
                    return link.get("href")
        return None

    def _extract_content_encoded(self, entry: Dict[str, Any]) -> Optional[str]:
        """content:encoded ì •ë³´ ì¶”ì¶œ"""
        return entry.get("content", [{}])[0].get("value") if "content" in entry else None

    def _parse_int(self, value: Any) -> Optional[int]:
        """ì •ìˆ˜ê°’ íŒŒì‹±"""
        try:
            return int(value) if value else None
        except (ValueError, TypeError):
            return None
