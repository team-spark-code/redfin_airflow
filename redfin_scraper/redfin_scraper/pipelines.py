# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html

import json
import sqlite3
from datetime import datetime
from typing import Dict, Any, Optional
import hashlib
import logging
from urllib.parse import urlparse
import mysql.connector
from mysql.connector import Error

from .items import RawRSSItem, ProcessedItem, PublicItem

logger = logging.getLogger(__name__)

# 100. MariaDB ì›ë³¸ RSS ë°ì´í„° ì €ì¥
class MariaDBPipeline:
    """MariaDB: RSS ì›ë³¸ ì „ì²´ ì €ì¥"""
    
    def __init__(self):
        self.conn = None
        self.cursor = None
        
    def open_spider(self, spider):
        """ìŠ¤íŒŒì´ë” ì‹œì‘ ì‹œ MariaDB ì—°ê²°"""
        try:
            self.conn = mysql.connector.connect(
                host="localhost",
                port=3306,
                user="redfin",
                password="Redfin7620!",
                database="redfin",
                charset="utf8mb4"
            )
            self.cursor = self.conn.cursor()
            logger.info("âœ… MariaDB ì—°ê²° ì„±ê³µ")
        except Error as e:
            logger.error(f"âŒ MariaDB ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
        
    def close_spider(self, spider):
        """ìŠ¤íŒŒì´ë” ì¢…ë£Œ ì‹œ DB ì—°ê²° í•´ì œ"""
        if self.cursor:
            self.cursor.close()
        if self.conn:
            self.conn.commit()
            self.conn.close()
            logger.info("ğŸ”Œ MariaDB ì—°ê²° í•´ì œ")
            
    def process_item(self, item: RawRSSItem, spider) -> RawRSSItem:
        """ì›ë³¸ RSS ë°ì´í„°ë¥¼ MariaDBì— ì €ì¥"""
        if not isinstance(item, RawRSSItem):
            return item
            
        # ìˆ˜ì§‘ ì‹œê°„ ì¶”ê°€
        item['collected_at'] = datetime.now().isoformat()
        
        try:
            # MariaDBì— ì €ì¥
            sql = '''
                INSERT INTO raw_rss_items (
                    guid, source, title, link, comments, atom_link_alternate,
                    atom_link_related, atom_link_self, feedburner_orig_link,
                    pub_date, updated, dc_creator, author, description,
                    content_encoded, category, dc_subject, enclosure_url,
                    enclosure_type, enclosure_length, media_content,
                    media_thumbnail, media_keywords, copyright,
                    creative_commons_license, source_feed, slash_comments,
                    collected_at, etag, last_modified, raw_xml, response_headers
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON DUPLICATE KEY UPDATE
                    title = VALUES(title),
                    description = VALUES(description),
                    content_encoded = VALUES(content_encoded),
                    updated_at = CURRENT_TIMESTAMP
            '''
            
            values = (
                item.get('guid'), item.get('source'), item.get('title'),
                item.get('link'), item.get('comments'), item.get('atom_link_alternate'),
                item.get('atom_link_related'), item.get('atom_link_self'), item.get('feedburner_orig_link'),
                item.get('pub_date'), item.get('updated'), item.get('dc_creator'), item.get('author'),
                item.get('description'), item.get('content_encoded'), item.get('category'), item.get('dc_subject'),
                item.get('enclosure_url'), item.get('enclosure_type'), item.get('enclosure_length'),
                item.get('media_content'), item.get('media_thumbnail'), item.get('media_keywords'),
                item.get('copyright'), item.get('creative_commons_license'), item.get('source_feed'),
                item.get('slash_comments'), item.get('collected_at'), item.get('etag'),
                item.get('last_modified'), item.get('raw_xml'), item.get('response_headers')
            )
            
            self.cursor.execute(sql, values)
            self.conn.commit()
            
            logger.info(f"ğŸ’¾ RSS ì•„ì´í…œ ì €ì¥ ì„±ê³µ: {item.get('title', 'Unknown')[:50]}...")
            
        except Error as e:
            logger.error(f"âŒ RSS ì•„ì´í…œ ì €ì¥ ì‹¤íŒ¨: {e}")
            self.conn.rollback()
            
        return item

# 200. ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸ (ê¸°ì¡´ ìœ ì§€)
class DataTransformationPipeline:
    """ë°ì´í„° ë³€í™˜ ë° ì •ì œ"""
    
    def process_item(self, item, spider):
        # ë°ì´í„° ì •ì œ ë¡œì§
        if 'title' in item:
            item['title'] = item['title'].strip()
        if 'description' in item:
            item['description'] = item['description'].strip()
        return item

# 300. ë¶„ì„ ë°ì´í„° ì €ì¥ (ê¸°ì¡´ ìœ ì§€)
class ProcessorPipeline:
    """ë¶„ì„ëœ ë°ì´í„° ì €ì¥"""
    
    def process_item(self, item, spider):
        # ë¶„ì„ ë¡œì§ (í–¥í›„ êµ¬í˜„)
        return item

# 400. ê³µê°œ API ë°ì´í„° ì €ì¥ (ê¸°ì¡´ ìœ ì§€)
class PublicAPIPipeline:
    """ê³µê°œ APIìš© ë°ì´í„° ì €ì¥"""
    
    def process_item(self, item, spider):
        # ê³µê°œìš© ë°ì´í„° í•„í„°ë§ (í–¥í›„ êµ¬í˜„)
        return item

# ê¸°ì¡´ SQLite íŒŒì´í”„ë¼ì¸ (ë°±ì—…ìš©)
class CollectorPipeline:
    """Collector Layer: RSS ì›ë³¸ ì „ì²´ ì €ì¥ (SQLite)"""
    
    def __init__(self):
        self.conn = None
        self.cursor = None
        
    def open_spider(self, spider):
        """ìŠ¤íŒŒì´ë” ì‹œì‘ ì‹œ DB ì—°ê²°"""
        self.conn = sqlite3.connect('raw_rss_data.db')
        self.cursor = self.conn.cursor()
        self._create_raw_table()
        
    def close_spider(self, spider):
        """ìŠ¤íŒŒì´ë” ì¢…ë£Œ ì‹œ DB ì—°ê²° í•´ì œ"""
        if self.conn:
            self.conn.commit()
            self.conn.close()
            
    def _create_raw_table(self):
        """ì›ë³¸ ë°ì´í„° ì €ì¥ í…Œì´ë¸” ìƒì„±"""
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS raw_rss_items (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                guid TEXT UNIQUE,
                source TEXT,
                title TEXT,
                link TEXT,
                comments TEXT,
                atom_link_alternate TEXT,
                atom_link_related TEXT,
                atom_link_self TEXT,
                feedburner_orig_link TEXT,
                pub_date TEXT,
                updated TEXT,
                dc_creator TEXT,
                author TEXT,
                description TEXT,
                content_encoded TEXT,
                category TEXT,
                dc_subject TEXT,
                enclosure_url TEXT,
                enclosure_type TEXT,
                enclosure_length TEXT,
                media_content TEXT,
                media_thumbnail TEXT,
                media_keywords TEXT,
                copyright TEXT,
                creative_commons_license TEXT,
                source_feed TEXT,
                slash_comments TEXT,
                collected_at TEXT,
                etag TEXT,
                last_modified TEXT,
                raw_xml TEXT,
                response_headers TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
    def process_item(self, item: RawRSSItem, spider) -> RawRSSItem:
        """ì›ë³¸ RSS ë°ì´í„° ì €ì¥"""
        if not isinstance(item, RawRSSItem):
            return item
            
        # ìˆ˜ì§‘ ì‹œê°„ ì¶”ê°€
        item['collected_at'] = datetime.now().isoformat()
        
        # DBì— ì €ì¥
        self.cursor.execute('''
            INSERT OR REPLACE INTO raw_rss_items (
                guid, source, title, link, comments, atom_link_alternate,
                atom_link_related, atom_link_self, feedburner_orig_link,
                pub_date, updated, dc_creator, author, description,
                content_encoded, category, dc_subject, enclosure_url,
                enclosure_type, enclosure_length, media_content,
                media_thumbnail, media_keywords, copyright,
                creative_commons_license, source_feed, slash_comments,
                collected_at, etag, last_modified, raw_xml, response_headers
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            item.get('guid'), item.get('source'), item.get('title'),
            item.get('link'), item.get('comments'), item.get('atom_link_alternate'),
            item.get('atom_link_related'), item.get('atom_link_self'), item.get('feedburner_orig_link'),
            item.get('pub_date'), item.get('updated'), item.get('dc_creator'), item.get('author'),
            item.get('description'), item.get('content_encoded'), item.get('category'), item.get('dc_subject'),
            item.get('enclosure_url'), item.get('enclosure_type'), item.get('enclosure_length'),
            item.get('media_content'), item.get('media_thumbnail'), item.get('media_keywords'),
            item.get('copyright'), item.get('creative_commons_license'), item.get('source_feed'),
            item.get('slash_comments'), item.get('collected_at'), item.get('etag'),
            item.get('last_modified'), item.get('raw_xml'), item.get('response_headers')
        ))
        
        return item
